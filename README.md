# ASL_FINGERSPELLING_DETECTION_APPLICATION
Our Project develops a smart gesture application an American Sign Language Finger Spelling translator. Using this We record videos while demonstrating American sign language for all English alphabets. These videos serve as training data, and we use them to train various algorithms. We build key points from the frames we extracted using PoseNet (a deep learning tensor flow model). And using key points, generated by PoseNet we crop the palm part from the frames, and we fed CNN model on the images to recognize the alphabets and using scikit-learn metrics we predict the accuracy based on the obtained and predicted value.
